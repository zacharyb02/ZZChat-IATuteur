SOURCE_URL: https://www.geeksforgeeks.org/machine-learning/image-classifier-using-cnn/
SUJET: CNN_DEEP_LEARNING

- Interview Prep
- Tutorials
- Tracks
- Python for Machine Learning
- Machine Learning with R
- Machine Learning Algorithms
- EDA
- Math for Machine Learning
- Machine Learning Interview Questions
- ML Projects
- Deep Learning
- NLP
- Computer vision
- Data Science
- Artificial Intelligence
# Image Classification using CNN
Image classification is a key task in machine learning where the goal is to assign a label to an image based on its content. Convolutional Neural Networks (CNNs) are specifically designed to analyze and interpret images. Unlike traditional neural networks, they are good at detecting patterns, shapes and textures by breaking down an image into smaller parts and learning from these details. By processing these patterns in multiple layers, it can identify increasingly complex features making them effective for tasks like classifying images of animals, objects or scenes. In this article, we will see how CNNs work and how to use them to build an image classifier.
## Key Components of CNNs
A Convolutional Neural Network (CNN) is made up of several layers, each designed to perform a specific function in processing images:
- Convolutional Layers : Filters or kernels that detect features such as edges or textures.
- ReLU Activation : Adds non-linearity, helping the model learn complex patterns.
- Pooling Layers : Reduce the dimensions of the image making the network more efficient while preserving important features.
- Fully Connected Layers : After feature extraction, these layers make the final prediction based on the detected patterns.
- Softmax Output : Converts the network’s output into probabilities, showing the likelihood of each class.
## How CNNs Work for Image Classification?
The process of image classification with a CNN involves several stages:
- Preprocessing the Image: Images need to be preprocessed before feeding them into the CNN. This includes resizing, normalizing and sometimes augmenting images to make the model more robust and reduce overfitting.
- Feature Extraction: CNNs automatically detect features from images, starting with simple features like edges and progressing to more complex patterns like objects or faces as we go deeper into the network.
- Classification: After extracting features, the fully connected layers use the learned information to classify the image. Based on the features detected, the model assigns the image to one of the predefined categories.
## Implementation of Image Classification using CNN
Lets see the implementation of Image Classification step-by-step:
### Step 1: Importing Libraries
We will be using Tensorflow and Matplotlib libraries for building, training and visualizing training and validation accuracy of the model.
```python
import tensorflow as tf
from tensorflow.keras import layers, models, datasets
import matplotlib.pyplot as plt
```
### Step 2: Downloading and Preparing the Dataset
Next we load the CIFAR-10 dataset and preprocess it. It consists of 60,000 32x32 color images across 10 categories.
- Scaling: We scale the image pixel values from [0, 255] to [0, 1] by dividing by 255.
- One-hot encoding: Converts the labels (0-9) into a one-hot vector (e.g., for label 2: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]).
```python
(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
num_classes = 10
y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_test  = tf.keras.utils.to_categorical(y_test , num_classes)
```
Output:
### Step 3: Building the CNN Model
Now, we define the CNN architecture and start with convolutional layers followed by max-pooling layers, flatten the output and then feed it into fully connected layers.
- Flatten Layer: Converts the 2D matrix into a 1D vector for the dense layers.
- Dense Layers: Fully connected layers used for decision making, with the final layer using softmax activation to predict probabilities.
```python
model = models.Sequential([
layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(32,32,3)),
layers.MaxPooling2D(2,2),
layers.Conv2D(64, (3,3), activation='relu', padding='same'),
layers.MaxPooling2D(2,2),
layers.Conv2D(64, (3,3), activation='relu', padding='same'),
layers.Flatten(),
layers.Dense(64, activation='relu'),
layers.Dense(num_classes, activation='softmax')
])
model.summary()
```
### Step 4: Compiling and Training the Model
We then compile the model by defining the optimizer, loss function and evaluation metric, followed by training. Adam optimizer is used as it adjusts the learning rate during training.
```python
model.compile(optimizer='adam',
loss='categorical_crossentropy',
metrics=['accuracy'])
history = model.fit(x_train, y_train,
epochs=15,
batch_size=64,
validation_split=0.2,
verbose=2)
```
### Step 5: Evaluating the Model
After training, we evaluate the model on the test dataset to check how well it performs on unseen data.
```python
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
print(f"Test accuracy = {test_acc:.3f}")
```
### Step 6: Plotting of Accuracy Curves
Finally, we visualize the training and validation accuracy during training using matplotlib.
```python
plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='val')
plt.legend()
plt.title('Accuracy')
plt.show()
```
## Benefits of Using CNNs for Image Classification
- Automatic Feature Learning: CNNs automatically learn relevant features from images, reducing the need for manual feature extraction and making them more adaptable to different tasks.
- Translation Invariance: They can recognize objects in images regardless of their position making them more robust to changes in image orientation.
- Efficiency: Pooling layers help reduce the image's size making the model more computationally efficient while retaining key features.
- Scalability: They can handle large datasets effectively, as they can process high volumes of data and continue improving with more examples.
## Challenges in Image Classification
While CNNs have several advantages, they also come with certain challenges that we need to be solve while implementing them.
- Overfitting: CNNs can overfit if the model is too complex or if there’s limited data. Techniques like data augmentation and dropout help mitigate this.
- Computational Demands: Training CNNs requires significant computational resources, often relying on high-performance GPUs or cloud services.
- Data Quality: High-quality, labeled datasets are important for accurate classification. Poor data can lead to inaccurate predictions.
- Long Training Times: Training deep CNN models can be computationally expensive and time-consuming, especially with large datasets.
### Explore
- Introduction to Machine Learning 8 min read
- Types of Machine Learning 7 min read
- What is Machine Learning Pipeline? 6 min read
- Applications of Machine Learning 3 min read
- Machine Learning with Python Tutorial 5 min read
- NumPy Tutorial - Python Library 3 min read
- Pandas Tutorial 4 min read
- Data Preprocessing in Python 4 min read
- EDA - Exploratory Data Analysis in Python 6 min read
- What is Feature Engineering? 5 min read
- Introduction to Dimensionality Reduction 4 min read
- Feature Selection Techniques in Machine Learning 4 min read
- Supervised Machine Learning 7 min read
- Linear Regression in Machine learning 14 min read
- Logistic Regression in Machine Learning 10 min read
- Decision Tree in Machine Learning 8 min read
- Random Forest Algorithm in Machine Learning 5 min read
- K-Nearest Neighbor(KNN) Algorithm 8 min read
- Support Vector Machine (SVM) Algorithm 9 min read
- Naive Bayes Classifiers 6 min read
- What is Unsupervised Learning 5 min read
- K means Clustering – Introduction 6 min read
- Hierarchical Clustering in Machine Learning 6 min read
- DBSCAN Clustering in ML - Density based clustering 6 min read
- Apriori Algorithm 6 min read
- Frequent Pattern Growth Algorithm 5 min read
- ECLAT Algorithm - ML 5 min read
- Principal Component Analysis (PCA) 7 min read
- Evaluation Metrics in Machine Learning 9 min read
- Regularization in Machine Learning 5 min read
- Cross Validation in Machine Learning 5 min read
- Hyperparameter Tuning 5 min read
- Underfitting and Overfitting in ML 3 min read
- Bias and Variance in Machine Learning 6 min read
- Reinforcement Learning 9 min read
- Semi-Supervised Learning in ML 5 min read
- Self-Supervised Learning (SSL) 6 min read
- Ensemble Learning 7 min read
- Machine Learning Interview Questions and Answers 15+ min read
- 100+ Machine Learning Projects with Source Code 5 min read