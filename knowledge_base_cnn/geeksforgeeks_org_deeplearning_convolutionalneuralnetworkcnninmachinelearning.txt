SOURCE_URL: https://www.geeksforgeeks.org/deep-learning/convolutional-neural-network-cnn-in-machine-learning/
SUJET: CNN_DEEP_LEARNING

# Convolutional Neural Network (CNN) in Machine Learning
Convolutional Neural Networks (CNNs) are deep learning models designed to process data with a grid-like topology such as images. They are the foundation for most modern computer vision applications to detect features within visual data.
### Key Components
- Convolutional Layers : These layers apply convolutional operations to input images using filters or kernels to detect features such as edges, textures and more complex patterns. Convolutional operations help preserve the spatial relationships between pixels.
- Pooling Layers : They downsample the spatial dimensions of the input, reducing the computational complexity and the number of parameters in the network. Max pooling is a common pooling operation where we select a maximum value from a group of neighboring pixels.
- Activation Functions : They introduce non-linearity to the model by allowing it to learn more complex relationships in the data.
- Fully Connected Layers : These layers are responsible for making predictions based on the high-level features learned by the previous layers. They connect every neuron in one layer to every neuron in the next layer.
## Working of CNN
- Input Image : CNN receives an input image which is preprocessed to ensure uniformity in size and format.
- Convolutional Layers : Filters are applied to the input image to extract features like edges, textures and shapes.
- Pooling Layers : The feature maps generated by the convolutional layers are downsampled to reduce dimensionality.
- Fully Connected Layers : The downsampled feature maps are passed through fully connected layers to produce the final output, such as a classification label.
- Output : The CNN outputs a prediction, such as the class of the image.
## Training a Convolutional Neural Network
CNNs are trained using a supervised learning approach. This means that the CNN is given a set of labeled training images. The CNN learns to map the input images to their correct labels.
The training process for a CNN involves the following steps:
- Data Preparation: The training images are preprocessed to ensure that they are all in the same format and size.
- Loss Function: A loss function is used to measure how well the CNN is performing on the training data. The loss function is typically calculated by taking the difference between the predicted labels and the actual labels of the training images.
- Optimizer: An optimizer is used to update the weights of the CNN in order to minimize the loss function.
- Backpropagation: Backpropagation is a technique used to calculate the gradients of the loss function with respect to the weights of the CNN. The gradients are then used to update the weights of the CNN using the optimizer.
## How to Evaluate CNN Models
Efficiency of CNN can be evaluated using a variety of criteria. Among the most popular metrics are:
- Accuracy: Accuracy is the percentage of test images that the CNN correctly classifies.
- Precision: Precision is the percentage of test images that the CNN predicts as a particular class and that are actually of that class.
- Recall: Recall is the percentage of test images that are of a particular class and that the CNN predicts as that class.
- F1 Score: The F1 Score is a harmonic mean of precision and recall. It is a good metric for evaluating the performance of a CNN on classes that are imbalanced.
## Different Types of CNN Models
1. LeNet: LeNet developed by Yann LeCun and his colleagues in the late 1990s was one of the first successful CNNs designed for handwritten digit recognition. It laid the foundation for modern CNNs and achieved high accuracy on the MNIST dataset which contains 70,000 images of handwritten digits (0-9).
2. AlexNet: AlexNet is a CNN architecture that was developed by Alex Krizhevsky, Ilya Sutskever and Geoffrey Hinton in 2012. It was the first CNN to win the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) a major image recognition competition. It consists of several layers of convolutional and pooling layers followed by fully connected layers. The architecture includes five convolutional layers, three pooling layers and three fully connected layers.
3. Resnet: ResNets (Residual Networks) are designed for image recognition and processing tasks. They are renowned for their ability to train very deep networks without overfitting making them highly effective for complex tasks. It introduces skip connections that allow the network to learn residual functions making it easier to train deep architecture.
4. GoogleNet: GoogleNet also known as InceptionNet is renowned for achieving high accuracy in image classification while using fewer parameters and computational resources compared to other state-of-the-art CNNs. The core component of GoogleNet allows the network to learn features at different scales simultaneously to enhance performance.
5. VGG: VGGs are developed by the Visual Geometry Group at Oxford, it uses small 3x3 convolutional filters stacked in multiple layers, creating a deep and uniform structure. Popular variants like VGG-16 and VGG-19 achieved state-of-the-art performance on the ImageNet dataset demonstrating the power of depth in CNNs.
## Applications
- Image classification: CNNs are the state-of-the-art models for image classification. They can be used to classify images into different categories such as cats and dogs.
- Object detection: It can be used to detect objects in images such as people, cars and buildings. They can also be used to localize objects in images which means that they can identify the location of an object in an image.
- Image segmentation: It can be used to segment images which means that they can identify and label different objects in an image. This is useful for applications such as medical imaging and robotics.
- Video analysis: It can be used to analyze videos such as tracking objects in a video or detecting events in a video. This is useful for applications such as video surveillance and traffic monitoring.
## Advantages
- High Accuracy : They can achieve high accuracy in various image recognition tasks.
- Efficiency : They are efficient, especially when implemented on GPUs.
- Robustness : They are robust to noise and variations in input data.
- Adaptability : It can be adapted to different tasks by modifying their architecture.
## Disadvantages
- Complexity : It can be complex and difficult to train, especially for large datasets.
- Resource-Intensive : It require significant computational resources for training and deployment.
- Data Requirements : They need large amounts of labeled data for training.
- Interpretability : They can be difficult to interpret making it challenging to understand their predictions.
G
- Deep Learning
- AI-ML-DS
- Neural Network