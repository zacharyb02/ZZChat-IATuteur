{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc4a360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (1.13.2)\n",
      "Collecting codecarbon\n",
      "  Using cached codecarbon-3.2.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-ollama) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-core) (0.6.7)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-core) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-core) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.6)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-community) (2.0.46)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-community) (2.3.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.6.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Collecting arrow (from codecarbon)\n",
      "  Using cached arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting click (from codecarbon)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fief-client[cli] (from codecarbon)\n",
      "  Using cached fief_client-0.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pandas>=2.3.3 (from codecarbon)\n",
      "  Downloading pandas-3.0.0-cp314-cp314-win_amd64.whl.metadata (19 kB)\n",
      "Collecting prometheus_client (from codecarbon)\n",
      "  Using cached prometheus_client-0.24.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: psutil>=6.0.0 in c:\\users\\mohaa\\appdata\\roaming\\python\\python314\\site-packages (from codecarbon) (7.2.2)\n",
      "Collecting py-cpuinfo (from codecarbon)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting nvidia-ml-py (from codecarbon)\n",
      "  Using cached nvidia_ml_py-13.590.48-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting rapidfuzz (from codecarbon)\n",
      "  Downloading rapidfuzz-3.14.3-cp314-cp314-win_amd64.whl.metadata (12 kB)\n",
      "Collecting questionary (from codecarbon)\n",
      "  Using cached questionary-2.1.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting rich (from codecarbon)\n",
      "  Using cached rich-14.3.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting typer (from codecarbon)\n",
      "  Using cached typer-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas>=2.3.3->codecarbon) (2.9.0.post0)\n",
      "Collecting tzdata (from pandas>=2.3.3->codecarbon)\n",
      "  Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mohaa\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.3.3->codecarbon) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mohaa\\appdata\\roaming\\python\\python314\\site-packages (from click->codecarbon) (0.4.6)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jwcrypto<2.0.0,>=1.4 (from fief-client[cli]->codecarbon)\n",
      "  Using cached jwcrypto-1.5.6-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting yaspin (from fief-client[cli]->codecarbon)\n",
      "  Using cached yaspin-3.4.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting sniffio (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cryptography>=3.4 (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon)\n",
      "  Using cached cryptography-46.0.4-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon)\n",
      "  Downloading cffi-2.0.0-cp314-cp314-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon)\n",
      "  Using cached pycparser-3.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in c:\\users\\mohaa\\appdata\\roaming\\python\\python314\\site-packages (from questionary->codecarbon) (3.0.52)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\mohaa\\appdata\\roaming\\python\\python314\\site-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.5.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->codecarbon)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mohaa\\appdata\\roaming\\python\\python314\\site-packages (from rich->codecarbon) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->codecarbon)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer->codecarbon)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting termcolor<4.0,>=3.2 (from yaspin->fief-client[cli]->codecarbon)\n",
      "  Using cached termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Using cached codecarbon-3.2.1-py3-none-any.whl (358 kB)\n",
      "Downloading pandas-3.0.0-cp314-cp314-win_amd64.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/9.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.8/9.9 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.6/9.9 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.7/9.9 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.7/9.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.5/9.9 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.8/9.9 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.9/9.9 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.2/9.9 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.9 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 4.3 MB/s  0:00:02\n",
      "Using cached arrow-1.4.0-py3-none-any.whl (68 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached fief_client-0.20.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached jwcrypto-1.5.6-py3-none-any.whl (92 kB)\n",
      "Using cached cryptography-46.0.4-cp311-abi3-win_amd64.whl (3.5 MB)\n",
      "Downloading cffi-2.0.0-cp314-cp314-win_amd64.whl (185 kB)\n",
      "Using cached nvidia_ml_py-13.590.48-py3-none-any.whl (50 kB)\n",
      "Using cached prometheus_client-0.24.1-py3-none-any.whl (64 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached pycparser-3.0-py3-none-any.whl (48 kB)\n",
      "Using cached questionary-2.1.1-py3-none-any.whl (36 kB)\n",
      "Downloading rapidfuzz-3.14.3-cp314-cp314-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 1.0/1.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 4.3 MB/s  0:00:00\n",
      "Using cached rich-14.3.1-py3-none-any.whl (309 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached typer-0.21.1-py3-none-any.whl (47 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Using cached yaspin-3.4.0-py3-none-any.whl (21 kB)\n",
      "Using cached termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: py-cpuinfo, nvidia-ml-py, tzdata, termcolor, sniffio, shellingham, rapidfuzz, pycparser, prometheus_client, mdurl, click, yaspin, questionary, pandas, markdown-it-py, httpx, cffi, arrow, rich, cryptography, typer, jwcrypto, fief-client, codecarbon\n",
      "\n",
      "   --- ------------------------------------  2/24 [tzdata]\n",
      "   --- ------------------------------------  2/24 [tzdata]\n",
      "   --- ------------------------------------  2/24 [tzdata]\n",
      "   --- ------------------------------------  2/24 [tzdata]\n",
      "   ------ ---------------------------------  4/24 [sniffio]\n",
      "   ---------- -----------------------------  6/24 [rapidfuzz]\n",
      "   ------------- --------------------------  8/24 [prometheus_client]\n",
      "   ---------------- ----------------------- 10/24 [click]\n",
      "   -------------------- ------------------- 12/24 [questionary]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   --------------------- ------------------ 13/24 [pandas]\n",
      "   ----------------------- ---------------- 14/24 [markdown-it-py]\n",
      "  Attempting uninstall: httpx\n",
      "   ----------------------- ---------------- 14/24 [markdown-it-py]\n",
      "    Found existing installation: httpx 0.28.1\n",
      "   ----------------------- ---------------- 14/24 [markdown-it-py]\n",
      "    Uninstalling httpx-0.28.1:\n",
      "   ----------------------- ---------------- 14/24 [markdown-it-py]\n",
      "      Successfully uninstalled httpx-0.28.1\n",
      "   ----------------------- ---------------- 14/24 [markdown-it-py]\n",
      "   ------------------------- -------------- 15/24 [httpx]\n",
      "   -------------------------- ------------- 16/24 [cffi]\n",
      "   ---------------------------- ----------- 17/24 [arrow]\n",
      "   ------------------------------ --------- 18/24 [rich]\n",
      "   ------------------------------ --------- 18/24 [rich]\n",
      "   ------------------------------ --------- 18/24 [rich]\n",
      "   ------------------------------- -------- 19/24 [cryptography]\n",
      "   ------------------------------- -------- 19/24 [cryptography]\n",
      "   ----------------------------------- ---- 21/24 [jwcrypto]\n",
      "   -------------------------------------- - 23/24 [codecarbon]\n",
      "   -------------------------------------- - 23/24 [codecarbon]\n",
      "   ---------------------------------------- 24/24 [codecarbon]\n",
      "\n",
      "Successfully installed arrow-1.4.0 cffi-2.0.0 click-8.3.1 codecarbon-3.2.1 cryptography-46.0.4 fief-client-0.20.0 httpx-0.27.2 jwcrypto-1.5.6 markdown-it-py-4.0.0 mdurl-0.1.2 nvidia-ml-py-13.590.48 pandas-3.0.0 prometheus_client-0.24.1 py-cpuinfo-9.0.0 pycparser-3.0 questionary-2.1.1 rapidfuzz-3.14.3 rich-14.3.1 shellingham-1.5.4 sniffio-1.3.1 termcolor-3.3.0 typer-0.21.1 tzdata-2025.3 yaspin-3.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Installation forc√©e des d√©pendances pour √©viter les erreurs de modules\n",
    "!{sys.executable} -m pip install langchain-ollama langchain-community langchain-core faiss-cpu codecarbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e790ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohaa\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from codecarbon import EmissionsTracker\n",
    "import os\n",
    "import time\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51137531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index FAISS charg√© avec succ√®s.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Configuration du mod√®le d'embeddings (doit √™tre le m√™me que pour la cr√©ation de l'index)\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "\n",
    "# Chargement de la base vectorielle locale\n",
    "# allow_dangerous_deserialization est n√©cessaire pour charger des fichiers .pkl localement\n",
    "vector_db = FAISS.load_local(\n",
    "    \"faiss_index_pfe\", \n",
    "    embeddings, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "print(\"Index FAISS charg√© avec succ√®s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0fe1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le Mistral pr√™t.\n"
     ]
    }
   ],
   "source": [
    "# Configuration du LLM Mistral\n",
    "# temperature=0 garantit des r√©ponses factuelles et non cr√©atives\n",
    "llm = ChatOllama(\n",
    "    model=\"mistral\", \n",
    "    temperature=0,\n",
    "    num_gpu=99,  # Tente d'utiliser le GPU au maximum\n",
    "    num_thread=4\n",
    ")\n",
    "\n",
    "print(\"Mod√®le Mistral pr√™t.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f5fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Fonction de recherche + r√©ponse modifi√©e\n",
    "def ask_question(query):\n",
    "    tracker = EmissionsTracker(save_to_file=True, output_dir=\".\")\n",
    "    tracker.start()\n",
    "    \n",
    "    start_time = time.time() # D√©but du chrono\n",
    "    # Recherche des documents pertinents (on r√©cup√®re les objets 'Document' entiers)\n",
    "    retriever = vector_db.as_retriever(search_type=\"mmr\", search_kwargs={'k': 6, 'fetch_k': 20})\n",
    "    docs = retriever.invoke(query)\n",
    "    # Pr√©paration du contexte texte\n",
    "    context_chunks = []\n",
    "    #print(\"\\n=== DOCUMENTS AND CONTEXT CHUNKS ===\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        # D√©coupe le texte en chunks\n",
    "        text = doc.page_content\n",
    "        context_chunks.append(text)\n",
    "    # Combine les chunks pour le LLM\n",
    "    context_for_llm = \"\\n\\n\".join(context_chunks)\n",
    "# Prompt syst√®me optimis√©e pour un r√¥le de Tuteur CNN\n",
    "    system_prompt = (\n",
    "    \"ROLE: CNN Specialist Assistant - STRICT DATA RETRIEVAL ONLY.\\n\\n\"\n",
    "    \n",
    "    \"=== THE GOLDEN RULE ===\\n\"\n",
    "    \"You are an AI assistant specialized ONLY in Convolutional Neural Networks (CNN). \"\n",
    "    \"Your knowledge is strictly limited to the provided documentation (RAG).\\n\\n\"\n",
    "    \n",
    "    \"=== STRICT BEHAVIORAL PROTOCOL ===\\n\"\n",
    "    \"If the answer is not explicitly found within the provided context, or if the question is outside the scope of Convolutional Neural Networks (CNN), you must respond EXACTLY and ONLY with: 'I don't know.' Do not provide any other text.\"\n",
    "    \n",
    "    \"2. 100% GROUNDING: Do not use your own training data. You are forbidden from \"\n",
    "    \"generating information that is not explicitly present in the provided context. \"\n",
    "    \"If the answer is missing from the context: 'I don't know.'\\n\"\n",
    "    \n",
    "    \"3. 100% CONTEXT: You must answer based ONLY on the documentation. Do not add outside \"\n",
    "    \"definitions of Quantum Computing. If the answer is not a CNN technical detail found in the text, \"\n",
    "    \"the response is: 'I don't know.'\\n\"\n",
    "    \n",
    "    \"4. NO FORMATTING/PREAMBLE: Do not use greetings (Hello, Hi). Start the answer \"\n",
    "    \"directly with the relevant technical content or the refusal string.\\n\\n\"\n",
    "    \n",
    "    \"=== VERIFICATION ===\\n\"\n",
    "    \"Question is CNN + In Context -> Direct answer.\\n\"\n",
    "    \"Question is NOT CNN OR Not In Context -> I don't know.\"\n",
    "    )\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=(\n",
    "            f\"STUDY CONTEXT:\\n{context_for_llm}\\n\\n\"\n",
    "            f\"QUESTION DE L'√âTUDIANT : {query}\\n\\n\"\n",
    "            \"R√âPONSE DU TUTEUR :\"\n",
    "        ))\n",
    "    ]\n",
    "    \n",
    "    # G√©n√©ration de la r√©ponse\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    end_time = time.time() # Fin du chrono\n",
    "    emissions = tracker.stop() # Fin du suivi carbone\n",
    "\n",
    "    inference_time = end_time - start_time\n",
    "    # On retourne la r√©ponse ET les documents sources\n",
    "    return response.content , inference_time, emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff7c339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 18:42:08] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "[codecarbon INFO @ 18:42:08] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 18:42:08] [setup] CPU Tracking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is maxpooling definition\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 18:42:10] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Windows OS detected: Please install Intel Power Gadget to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 18:42:10] CPU Model on constant consumption mode: Intel(R) Core(TM) i5-9300H CPU @ 2.40GHz\n",
      "[codecarbon WARNING @ 18:42:10] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 18:42:10] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 18:42:10] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 18:42:10] The below tracking methods have been set up:\n",
      "                RAM Tracking Method: RAM power estimation model\n",
      "                CPU Tracking Method: global constant\n",
      "                GPU Tracking Method: pynvml\n",
      "            \n",
      "[codecarbon INFO @ 18:42:10] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 18:42:10]   Platform system: Windows-11-10.0.26200-SP0\n",
      "[codecarbon INFO @ 18:42:10]   Python version: 3.14.0\n",
      "[codecarbon INFO @ 18:42:10]   CodeCarbon version: 3.2.1\n",
      "[codecarbon INFO @ 18:42:10]   Available RAM : 7.851 GB\n",
      "[codecarbon INFO @ 18:42:10]   CPU count: 8 thread(s) in 8 physical CPU(s)\n",
      "[codecarbon INFO @ 18:42:10]   CPU model: Intel(R) Core(TM) i5-9300H CPU @ 2.40GHz\n",
      "[codecarbon INFO @ 18:42:10]   GPU count: 1\n",
      "[codecarbon INFO @ 18:42:10]   GPU model: 1 x NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "[codecarbon INFO @ 18:42:14] Emissions data (if any) will be saved to file c:\\Users\\mohaa\\Desktop\\IA\\AI-Tutor\\src\\emissions.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POOLING LAYERS\n",
      "===============\n",
      "\n",
      "Q1: What is pooling and why use it?\n",
      "A: Pooling reduces spatial dimensions to:\n",
      "- Decrease number of parameters and computations\n",
      "- Create translation invariance\n",
      "- Expand receptive field\n",
      "- Reduce overfitting\n",
      "\n",
      "Q2: What are the different types of pooling?\n",
      "A:\n",
      "import torch.nn as nn\n",
      "\n",
      "# Max Pooling (most common)\n",
      "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
      "\n",
      "# Average Pooling\n",
      "avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
      "\n",
      "# Global Average Pooling\n",
      "global_avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
      "\n",
      "# Global Max Pooling\n",
      "global_maxpool = nn.AdaptiveMaxPool2d((1, 1))\n",
      "\n",
      "Q3: Difference between Max and Average Pooling?\n",
      "A:\n",
      "- Max Pooling: Takes maximum value in region\n",
      "  ‚Üí Better for detecting features (presence/absence)\n",
      "  ‚Üí More robust to noise\n",
      "  \n",
      "- Average Pooling: Computes average of region\n",
      "  ‚Üí Smooths features\n",
      "  ‚Üí Often used in final layer (Global Average Pooling)\n",
      "\n",
      "processed concurrently. If not set, the tf.data runtime decides what it\n",
      "should be based on available CPU. If num_parallel_calls is set to tf.data.AUTOTUNE , the cycle_length argument identifies\n",
      "the maximum degree of parallelism. block_length (Optional.) The number of consecutive elements to produce\n",
      "from each input element before cycling to another input element. If not\n",
      "set, defaults to 1. num_parallel_calls (Optional.) If specified, the implementation creates a\n",
      "threadpool, which is used to fetch inputs from cycle elements\n",
      "asynchronously and in parallel. The default behavior is to fetch inputs\n",
      "from cycle elements synchronously with no parallelism. If the value tf.data.AUTOTUNE is used, then the number of parallel\n",
      "calls is set dynamically based on available CPU. deterministic (Optional.) When num_parallel_calls is specified, if this\n",
      "\n",
      "2.4-\n",
      "Couche d‚Äôagr¬¥egation et de sous-¬¥echantillonnage\n",
      "Le sous-¬¥echantillonnage (pooling) des cartes obtenues par les couches pr¬¥ec¬¥edentes a pour objectif d‚Äôassurer\n",
      "une robustesse au bruit et aux distorsions.\n",
      "La sortie d‚Äôune couche d‚Äôagr¬¥egation l (Ô¨Ågure 2-4) est compos¬¥ee de n(l) = n(l‚àí1) cartes de taille r¬¥eduite.\n",
      "En g¬¥en¬¥eral, l‚Äôagr¬¥egation est effectu¬¥ee en d¬¥eplac¬∏ant dans les cartes d‚Äôentr¬¥ee une fenÀÜetre de taille 2p √ó 2p\n",
      "toutes les q positions (il y a recouvrement si q < p et non recouvrement sinon), et en calculant, pour chaque\n",
      "position de la fenÀÜetre, une seule valeur, affect¬¥ee `a la position centrale dans la carte de sortie. On distingue\n",
      "g¬¥en¬¥eralement deux types d‚Äôagr¬¥egation :\n",
      "‚àí1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "ReLU(x) = max(0,x)\n",
      "LeakyReLU(x,Œ±) =\n",
      "(\n",
      "x\n",
      "si x > 0\n",
      "Œ±x\n",
      "sinon\n",
      "(\n",
      "x\n",
      "si x > 0\n",
      "Œ±(ex ‚àí1)\n",
      "sinon\n",
      "SeLU(x,Œ±,Œª) =\n",
      "(\n",
      "Œªx\n",
      "si x > 0\n",
      "ŒªŒ±(ex ‚àí1)\n",
      "sinon\n",
      "FIGURE 2-3 ‚Äì Quelques fonctions d‚Äôactivation\n",
      "\n",
      "MAX POOLING: Takes maximum value in region (downsampling).\n",
      "\n",
      "METRIC: Performance measure (accuracy, F1, mAP).\n",
      "\n",
      "MOBILENET: Lightweight architecture for mobile (Google).\n",
      "\n",
      "N\n",
      "=\n",
      "NAS: Neural Architecture Search, AI designs architectures automatically.\n",
      "\n",
      "NORMALIZATION: Data scaling (0-1 or mean 0, std 1).\n",
      "\n",
      "O\n",
      "=\n",
      "ONNX: Open Neural Network Exchange, interoperable model format.\n",
      "\n",
      "OPTIMIZER: Weight update algorithm (SGD, Adam, etc.).\n",
      "\n",
      "OVERFITTING: Memorizes training without generalization (train acc >> val acc).\n",
      "\n",
      "P\n",
      "=\n",
      "PADDING: Adding zeros around image to maintain dimension.\n",
      "\n",
      "PARAMETER: Learned network weight (millions typically).\n",
      "\n",
      "POOLING: Reducing spatial dimensions (Max, Average).\n",
      "\n",
      "PRECISION: TP / (TP + FP), proportion of correct positive predictions.\n",
      "\n",
      "R\n",
      "=\n",
      "RECALL: TP / (TP + FN), proportion of positives detected.\n",
      "\n",
      "RECEPTIVE FIELD: Region of input image influencing a given neuron.\n",
      "\n",
      "keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
      "prune_low_magnitude(\n",
      "keras.layers.Conv2D(\n",
      "64, 5, padding='same',\n",
      "name=\"structural_pruning\"),\n",
      "**pruning_params_2_by_4),\n",
      "keras.layers.BatchNormalization(),\n",
      "keras.layers.ReLU(),\n",
      "keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
      "keras.layers.Flatten(),\n",
      "prune_low_magnitude(\n",
      "keras.layers.Dense(\n",
      "1024, activation='relu',\n",
      "name=\"structural_pruning_dense\"),\n",
      "**pruning_params_2_by_4),\n",
      "keras.layers.Dropout(0.4),\n",
      "keras.layers.Dense(10)\n",
      "model.compile(optimizer='adam',\n",
      "loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
      "metrics=['accuracy'])\n",
      "model.summary()\n",
      "```python\n",
      "2026-01-14 12:38:44.733943: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Model: \"sequential\"\n",
      "\n",
      "global_max_pooling2d (Glob  (None, 16)                0\n",
      "alMaxPooling2D)\n",
      "Total params: 18672 (72.94 KB)\n",
      "Trainable params: 18672 (72.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "Model: \"autoencoder\"\n",
      "Layer (type)                Output Shape              Param #\n",
      "img (InputLayer)            [(None, 28, 28, 1)]       0\n",
      "conv2d (Conv2D)             (None, 26, 26, 16)        160\n",
      "conv2d_1 (Conv2D)           (None, 24, 24, 32)        4640\n",
      "max_pooling2d (MaxPooling2  (None, 8, 8, 32)          0\n",
      "conv2d_2 (Conv2D)           (None, 6, 6, 32)          9248\n",
      "conv2d_3 (Conv2D)           (None, 4, 4, 16)          4624\n",
      "global_max_pooling2d (Glob  (None, 16)                0\n",
      "alMaxPooling2D)\n",
      "reshape (Reshape)           (None, 4, 4, 1)           0\n",
      "conv2d_transpose (Conv2DTr  (None, 6, 6, 16)          160\n",
      "anspose)\n",
      "conv2d_transpose_1 (Conv2D  (None, 8, 8, 32)          4640\n",
      "Transpose)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 18:42:29] Energy consumed for RAM : 0.000042 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 18:42:29] Delta energy consumed for CPU with constant : 0.000751 kWh, power : 180.0 W\n",
      "[codecarbon INFO @ 18:42:29] Energy consumed for All CPU : 0.000751 kWh\n",
      "[codecarbon INFO @ 18:42:29] Energy consumed for all GPUs : 0.000034 kWh. Total GPU Power : 8.062421632643536 W\n",
      "[codecarbon INFO @ 18:42:29] 0.000827 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 18:42:44] Energy consumed for RAM : 0.000083 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 18:42:44] Delta energy consumed for CPU with constant : 0.000750 kWh, power : 180.0 W\n",
      "[codecarbon INFO @ 18:42:44] Energy consumed for All CPU : 0.001501 kWh\n",
      "[codecarbon INFO @ 18:42:44] Energy consumed for all GPUs : 0.000044 kWh. Total GPU Power : 2.397759444786034 W\n",
      "[codecarbon INFO @ 18:42:44] 0.001628 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 18:42:59] Energy consumed for RAM : 0.000125 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 18:42:59] Delta energy consumed for CPU with constant : 0.000750 kWh, power : 180.0 W\n",
      "[codecarbon INFO @ 18:42:59] Energy consumed for All CPU : 0.002251 kWh\n",
      "[codecarbon INFO @ 18:42:59] Energy consumed for all GPUs : 0.000053 kWh. Total GPU Power : 2.3369148373561752 W\n",
      "[codecarbon INFO @ 18:42:59] 0.002430 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 18:43:14] Energy consumed for RAM : 0.000167 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 18:43:14] Delta energy consumed for CPU with constant : 0.000750 kWh, power : 180.0 W\n",
      "[codecarbon INFO @ 18:43:14] Energy consumed for All CPU : 0.003001 kWh\n",
      "[codecarbon INFO @ 18:43:14] Energy consumed for all GPUs : 0.000148 kWh. Total GPU Power : 22.804940599485455 W\n",
      "[codecarbon INFO @ 18:43:14] 0.003317 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 18:43:29] Energy consumed for RAM : 0.000208 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 18:43:29] Delta energy consumed for CPU with constant : 0.000750 kWh, power : 180.0 W\n",
      "[codecarbon INFO @ 18:43:29] Energy consumed for All CPU : 0.003752 kWh\n",
      "[codecarbon INFO @ 18:43:29] Energy consumed for all GPUs : 0.000244 kWh. Total GPU Power : 22.981100723507275 W\n",
      "[codecarbon INFO @ 18:43:29] 0.004204 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 18:43:40] Energy consumed for RAM : 0.000239 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 18:43:40] Delta energy consumed for CPU with constant : 0.000555 kWh, power : 180.0 W\n",
      "[codecarbon INFO @ 18:43:40] Energy consumed for All CPU : 0.004307 kWh\n",
      "[codecarbon INFO @ 18:43:40] Energy consumed for all GPUs : 0.000320 kWh. Total GPU Power : 24.71634650372847 W\n",
      "[codecarbon INFO @ 18:43:40] 0.004867 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== METRIQUES DE PERFORMANCE ===\n",
      "‚è±Ô∏è Temps d'inf√©rence : 86.15 secondes\n",
      "üå± √âmissions g√©n√©r√©es : 0.0002727148 kg CO2\n",
      "------------------------------\n",
      "\n",
      "=== TUTOR RESPONSE ===\n",
      " MaxPooling is a pooling operation that reduces spatial dimensions by taking the maximum value in a region (downsampling).\n"
     ]
    }
   ],
   "source": [
    "# Question √† poser\n",
    "query = \"What is maxpooling definition\" \n",
    "\n",
    "print(f\"Question: {query}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Appel de la fonction\n",
    "answer, duration, co2 = ask_question(query)\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "print(\"\\n=== METRIQUES DE PERFORMANCE ===\")\n",
    "print(f\"‚è±Ô∏è Temps d'inf√©rence : {duration:.2f} secondes\")\n",
    "print(f\"üå± √âmissions g√©n√©r√©es : {co2:.10f} kg CO2\")\n",
    "print(\"-\" * 30)\n",
    "print(\"\\n=== TUTOR RESPONSE ===\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
