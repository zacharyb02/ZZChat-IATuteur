COMPLETE GLOSSARY - ESSENTIAL CNN TERMS
=========================================

A
=
ACTIVATION: Non-linear function (ReLU, sigmoid, tanh) applied to neuron outputs.

ADAM: Popular adaptive optimizer, combines momentum and RMSprop.

ADVERSARIAL EXAMPLE: Imperceptibly modified image to fool CNN.

ALEXNET: CNN architecture (2012) that revolutionized deep learning, ImageNet winner.

ARCHITECTURE: Network structure (number of layers, types, connections).

AUGMENTATION: Creating image variations (rotation, flip, etc.) to increase dataset.

B
=
BACKBONE: Feature extraction part of CNN (before classification layers).

BACKPROPAGATION: Algorithm to calculate gradients and update weights.

BATCH: Group of examples processed together (typically 16-128).

BATCH NORMALIZATION: Normalizes activations by batch to stabilize training.

BCE: Binary Cross Entropy, loss for binary classification.

BIAS: Additional term in neuron (wx + b). Also: bias in data.

C
=
CHANNEL: Depth dimension (RGB = 3 channels, feature maps = 64 channels, etc.).

CHECKPOINT: Model save during training to resume if crash.

CIFAR-10/100: Classic datasets (60K 32x32 images, 10 or 100 classes).

CNN: Convolutional Neural Network, network with convolutional layers.

CONVOLUTION: Mathematical operation applying filter to image.

D
=
DATASET: Collection of images with labels for training.

DEEPLAB: Architecture for semantic segmentation.

DEPTH: Number of layers in network.

DROPOUT: Regularization randomly deactivating neurons during training.

E
=
EARLY STOPPING: Stop training when validation stops improving.

EFFICIENTNET: Architecture family with optimal scaling (Google, 2019).

EMBEDDING: Learned vector representation (e.g., 512-dim for face).

EPOCH: One complete pass through entire training dataset.

F
=
FASTER R-CNN: Two-stage architecture for object detection.

FEATURE: Visual characteristic learned (edge, texture, object).

FEATURE MAP: Output of convolutional layer (3D tensor).

FINE-TUNING: Adjusting pretrained model on new dataset.

FOCAL LOSS: Loss for imbalanced classes (RetinaNet).

F1-SCORE: Harmonic mean of precision/recall.

G
=
GAN: Generative Adversarial Network, for image generation.

GLOBAL AVERAGE POOLING: Average of each feature map → 1 value.

GPU: Graphics Processing Unit, essential for fast CNN training.

GRAD-CAM: Gradient-weighted Class Activation Mapping, attention visualization.

GRADIENT: Partial derivative of loss with respect to weights.

H
=
HYPERPARAMETER: Non-learned parameter (learning rate, batch size, dropout rate).

I
=
IMAGENET: 1.2M image dataset, 1000 classes. Main benchmark 2010-2017.

INCEPTION: Module with parallel multi-scale convolutions (GoogLeNet).

INFERENCE: Using trained model to predict (vs training).

IOU: Intersection over Union, metric for detection/segmentation.

K
=
KERNEL: Convolution filter (weight matrix). Synonym: filter.

L
=
LABEL: Ground truth label (class, bounding box, mask).

LAYER: Network layer (Conv, FC, Pooling, etc.).

LEARNING RATE: Step size in gradient descent (crucial hyperparameter).

LENET: First CNN (Yann LeCun, 1989-1998).

LOSS FUNCTION: Function measuring error between prediction and truth.

M
=
MASK R-CNN: Instance segmentation architecture (Faster R-CNN extension).

MAX POOLING: Takes maximum value in region (downsampling).

METRIC: Performance measure (accuracy, F1, mAP).

MOBILENET: Lightweight architecture for mobile (Google).

N
=
NAS: Neural Architecture Search, AI designs architectures automatically.

NORMALIZATION: Data scaling (0-1 or mean 0, std 1).

O
=
ONNX: Open Neural Network Exchange, interoperable model format.

OPTIMIZER: Weight update algorithm (SGD, Adam, etc.).

OVERFITTING: Memorizes training without generalization (train acc >> val acc).

P
=
PADDING: Adding zeros around image to maintain dimension.

PARAMETER: Learned network weight (millions typically).

POOLING: Reducing spatial dimensions (Max, Average).

PRECISION: TP / (TP + FP), proportion of correct positive predictions.

R
=
RECALL: TP / (TP + FN), proportion of positives detected.

RECEPTIVE FIELD: Region of input image influencing a given neuron.

REGULARIZATION: Techniques to avoid overfitting (dropout, weight decay).

RELU: Rectified Linear Unit, activation f(x) = max(0, x). Most used.

RESNET: Residual Network (2015), skip connections. Revolutionary.

S
=
SEGMENTATION: Pixel-by-pixel classification.

SGD: Stochastic Gradient Descent, basic but effective optimizer.

SIGMOID: Activation f(x) = 1/(1+e^-x), output 0-1.

SKIP CONNECTION: Connection jumping layers (ResNet, U-Net).

SOFTMAX: Function converting logits to probabilities.

STRIDE: Convolution filter step (stride 2 = divides size by 2).

T
=
TENSORRT: NVIDIA inference optimizer (very fast).

TRANSFER LEARNING: Reusing pretrained model for new task.

U
=
UNDERFITTING: Model too simple, poor performance on train AND val.

U-NET: Encoder-decoder architecture for segmentation (2015).

V
=
VALIDATION SET: Data subset for hyperparameter tuning (distinct from test).

VANISHING GRADIENT: Gradients → 0 in deep layers, stop learning.

VGG: Architecture stacking 3x3 convs (Oxford, 2014). Simple but effective.

VIT: Vision Transformer, applies Transformers to vision (2020).

W
=
WEIGHT: Connection weight between neurons (learned parameters).

WEIGHT DECAY: L2 regularization, penalizes high weights.

Y
=
YOLO: You Only Look Once, real-time one-stage object detection.

=======================================
END OF GLOSSARY
=======================================
