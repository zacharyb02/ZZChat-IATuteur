CONVOLUTION LAYERS
==================

Q1: How does 2D convolution work?
A: Convolution applies a filter (kernel) to the input image by computing the dot product between the kernel and each local region of the image.

Q2: What is a convolution kernel/filter?
A: A kernel is a small weight matrix that detects specific patterns (edges, textures, shapes). Common sizes: 3x3, 5x5, 7x7.

Q3: How to implement different types of convolutions?
A:

import torch
import torch.nn as nn

# Standard convolution
conv_standard = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)

# Strided convolution (downsampling)
conv_stride = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1)

# Dilated convolution (atrous)
conv_dilated = nn.Conv2d(3, 64, kernel_size=3, dilation=2, padding=2)

# Depthwise separable convolution
conv_depthwise = nn.Conv2d(64, 64, kernel_size=3, groups=64, padding=1)

# 1x1 convolution (pointwise)
conv_pointwise = nn.Conv2d(64, 128, kernel_size=1)

Q4: What is padding and why use it?
A: Padding adds zeros around the image to:
- Preserve spatial dimensions
- Allow the kernel to process image edges
- Control output size

Types:
- VALID (no padding): Output = (Input - Kernel) / Stride + 1
- SAME (padding): Output = Input / Stride

Q5: How to create a reusable convolution block?
A:

class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super(ConvBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.relu(x)
        return x

Q6: What is transposed convolution?
A: Transposed convolution = learned upsampling, used to increase resolution (segmentation, GANs).

upconv = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)
x = torch.randn(1, 64, 16, 16)
output = upconv(x)  # [1, 32, 32, 32] - doubles size

Q7: How to calculate the number of parameters in Conv2d?
A: Formula: Params = (Kernel_H × Kernel_W × In_Channels + 1) × Out_Channels

conv = nn.Conv2d(3, 64, kernel_size=3)
params = sum(p.numel() for p in conv.parameters())
print(f"Number of parameters: {params}")  # 1,792

Q8: How to implement separable convolution?
A:

class SeparableConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):
        super(SeparableConv2d, self).__init__()
        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, 
                                   padding=padding, groups=in_channels)
        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)
    
    def forward(self, x):
        x = self.depthwise(x)
        x = self.pointwise(x)
        return x

# Parameter comparison
conv_standard = nn.Conv2d(64, 128, 3, padding=1)
conv_separable = SeparableConv2d(64, 128, 3, padding=1)

params_standard = sum(p.numel() for p in conv_standard.parameters())
params_separable = sum(p.numel() for p in conv_separable.parameters())

print(f"Standard: {params_standard} params")    # 73,728
print(f"Separable: {params_separable} params")  # 8,832 (89% reduction!)
