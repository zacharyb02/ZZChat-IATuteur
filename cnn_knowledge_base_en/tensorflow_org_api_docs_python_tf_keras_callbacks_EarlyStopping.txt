# tf.keras.callbacks.EarlyStoppingStay organized with collectionsSave and categorize content based on your preferences.
Stop training when a monitored metric has stopped improving.
```python
tf.keras.callbacks.EarlyStopping(
monitor='val_loss',
min_delta=0,
patience=0,
verbose=0,
mode='auto',
baseline=None,
restore_best_weights=False,
start_from_epoch=0
### Used in the notebooks
- Simple audio recognition: Recognizing keywords
- Transfer learning with YAMNet for environmental sound classification
- Introduction to the Keras Tuner
Assuming the goal of a training is to minimize the loss. With this, the
metric to be monitored would be 'loss' , and mode would be 'min' . A model.fit() training loop will check at end of every epoch whether
the loss is no longer decreasing, considering the min_delta and patience if applicable. Once it's found no longer decreasing, model.stop_training is marked True and the training terminates.
The quantity to be monitored needs to be available in logs dict.
To make it so, pass the loss or metrics at model.compile() .
## Args
monitor Quantity to be monitored. Defaults to "val_loss" . min_delta Minimum change in the monitored quantity to qualify as an
improvement, i.e. an absolute change of less than min_delta, will
count as no improvement. Defaults to 0 . patience Number of epochs with no improvement after which training will
be stopped. Defaults to 0 . verbose Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1 displays
messages when the callback takes an action. Defaults to 0 . mode One of {"auto", "min", "max"} . In min mode, training will stop
when the quantity monitored has stopped decreasing; in "max" mode
it will stop when the quantity monitored has stopped increasing; in "auto" mode, the direction is automatically inferred from the name
of the monitored quantity. Defaults to "auto" . baseline Baseline value for the monitored quantity. If not None ,
training will stop if the model doesn't show improvement over the
baseline. Defaults to None . restore_best_weights Whether to restore model weights from the epoch
with the best value of the monitored quantity. If False , the model
weights obtained at the last step of training are used. An epoch
will be restored regardless of the performance relative to the baseline . If no epoch improves on baseline , training will run
for patience epochs and restore weights from the best epoch in
that set. Defaults to False . start_from_epoch Number of epochs to wait before starting to monitor
improvement. This allows for a warm-up period in which no
improvement is expected and thus training will not be stopped.
Defaults to 0 .
```python
callback = keras.callbacks.EarlyStopping(monitor='loss',
patience=3)
# This callback will stop the training when there is no improvement in
# the loss for three consecutive epochs.
model = keras.models.Sequential([keras.layers.Dense(10)])
model.compile(keras.optimizers.SGD(), loss='mse')
history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),
epochs=10, batch_size=1, callbacks=[callback],
verbose=0)
len(history.history['loss'])  # Only 4 epochs are run.
## Attributes
## Methods
### get_monitor_value
```python
get_monitor_value(
### on_batch_begin
```python
on_batch_begin(
batch, logs=None
A backwards compatibility alias for on_train_batch_begin .
### on_batch_end
```python
on_batch_end(
batch, logs=None
A backwards compatibility alias for on_train_batch_end .
### on_epoch_begin
```python
on_epoch_begin(
epoch, logs=None
Called at the start of an epoch.
Subclasses should override for any actions to run. This function should
only be called during TRAIN mode.
epoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this
method but that may change in the future.
### on_epoch_end
```python
on_epoch_end(
epoch, logs=None
epoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the
validation epoch if validation is performed. Validation result
keys are prefixed with val_ . For training epoch, the values of
the Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .
### on_predict_batch_begin
```python
on_predict_batch_begin(
batch, logs=None
Called at the beginning of a batch in predict methods.
Subclasses should override for any actions to run.
Note that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.
batch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this
method but that may change in the future.
### on_predict_batch_end
```python
on_predict_batch_end(
batch, logs=None
Called at the end of a batch in predict methods.
batch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.
### on_predict_begin
```python
on_predict_begin(
logs=None
Called at the beginning of prediction.
logs Dict. Currently no data is passed to this argument for this
method but that may change in the future.
### on_predict_end
```python
on_predict_end(
logs=None
Called at the end of prediction.
### on_test_batch_begin
```python
on_test_batch_begin(
batch, logs=None
Called at the beginning of a batch in evaluate methods.
Also called at the beginning of a validation batch in the fit methods, if validation data is provided.
### on_test_batch_end
```python
on_test_batch_end(
batch, logs=None
Called at the end of a batch in evaluate methods.
Also called at the end of a validation batch in the fit methods, if validation data is provided.
### on_test_begin
```python
on_test_begin(
logs=None
Called at the beginning of evaluation or validation.
### on_test_end
```python
on_test_end(
logs=None
Called at the end of evaluation or validation.
logs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method
but that may change in the future.
### on_train_batch_begin
```python
on_train_batch_begin(
batch, logs=None
Called at the beginning of a training batch in fit methods.
### on_train_batch_end
```python
on_train_batch_end(
batch, logs=None
Called at the end of a training batch in fit methods.
### on_train_begin
```python
on_train_begin(
logs=None
Called at the beginning of training.
### on_train_end
```python
on_train_end(
logs=None
logs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but
that may change in the future.
### set_model
```python
set_model(
model
### set_params
```python
set_params(
params
Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License , and code samples are licensed under the Apache 2.0 License . For details, see the Google Developers Site Policies . Java is a registered trademark of Oracle and/or its affiliates. Some content is licensed under the numpy license .