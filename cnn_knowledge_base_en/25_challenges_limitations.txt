CHALLENGES AND LIMITATIONS
===========================

Q1: What is an adversarial example and why is it problematic?
A: An adversarial example is an image imperceptibly modified to fool the CNN:

FAMOUS EXAMPLE:
- Panda image + imperceptible noise = "gibbon" with 99% confidence
- Modification invisible to human eye
- Works consistently

DANGERS:
- Security: fool face recognition
- Autonomous driving: STOP sign → 50 sign
- Medical: false diagnosis

DEFENSES:
- Adversarial training
- Defensive distillation
- Input transformation
- Perturbation detection

FUNDAMENTAL PROBLEM: no complete solution to date

Q2: Why are CNNs sensitive to data bias?
A: CNNs learn AND amplify biases:

TYPES OF BIAS:

1. SELECTION BIAS:
- Non-representative dataset
- Example: ImageNet overrepresents Western countries

2. LABEL BIAS:
- Biased annotations
- Example: gendered professions

3. ASSOCIATION BIAS:
- Spurious correlations in data
- Example: "cow" associated with "green grass"

4. DEMOGRAPHIC BIAS:
- Face recognition less accurate for non-white people
- Ethnically imbalanced datasets

SOLUTIONS:
- Diverse and balanced datasets
- Bias auditing
- Fairness constraints

Q3: What are semantic understanding limits?
A: CNNs "see" but don't truly "understand":

TEXTURE vs SHAPE:
- CNNs rely heavily on texture
- Humans rely on shape
- Example: cat photo with elephant texture → CNN says "elephant"

GLOBAL CONTEXT:
- Difficulty reasoning about complete scene

CAUSALITY:
- Learn correlations, not causality
- Example: detects ruler via hand holding it

COMMON SENSE:
- No world knowledge
- Example: giraffe in fridge judged normal if visually coherent

COUNTING:
- Difficulty precisely counting beyond 5-10 objects

Q4: What are ethical and societal challenges?
A: Deep societal impact of CNNs:

MASS SURVEILLANCE:
- Face recognition everywhere
- Individual tracking
- Privacy violation
- Authoritarian use

DEEPFAKES:
- Realistic fake videos
- Disinformation
- Non-consensual pornography

EMPLOYMENT:
- Job automation (radiologists, drivers)
- Worker displacement
- Increased inequalities

DISCRIMINATION:
- Racial bias in face recognition
- Biased AI-based loan/insurance denial

RESPONSIBILITY:
- Who's responsible if CNN causes accident?
- AI-generated art intellectual property

NEEDED REGULATION:
- EU AI Act
- Red lines (autonomous weapons)
- Mandatory algorithmic auditing
