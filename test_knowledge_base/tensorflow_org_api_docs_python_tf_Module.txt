

# tf.ModuleStay organized with collectionsSave and categorize content based on your preferences.


tf.Module(
    name=None
)




### Used in the notebooks
- Introduction to modules, layers, and models
- Distributed training with Core APIs and DTensor
- Logistic regression for binary classification with Core APIs
- Multilayer perceptrons for digit recognition with Core APIs
- Distributed training with DTensors
- Neural machine translation with a Transformer and Keras
functions which apply to user input. For example a dense layer in a neural


class Dense(tf.Module):
  def __init__(self, input_dim, output_size, name=None):
    super().__init__(name=name)
    self.w = tf.Variable(
      tf.random.normal([input_dim, output_size]), name='w')
    self.b = tf.Variable(tf.zeros([output_size]), name='b')
  def __call__(self, x):
    y = tf.matmul(x, self.w) + self.b
    return tf.nn.relu(y)


You can use the Dense layer as you would expect:


d = Dense(input_dim=3, output_size=2)
d(tf.ones([1, 3]))
<tf.Tensor: shape=(1, 2), dtype=float32, numpy=..., dtype=float32)>




    (<tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=...,
    dtype=float32)>,
    <tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=..., dtype=float32)>)


Subclasses of tf.Module can also take advantage of the _flatten method
to group operations in TensorBoard and create hierarchies for variable names
to inspect in TensorBoard. You can enter the name scope explicitly using with self.name_scope: or you can annotate methods (apart from __init__ )


class MLP(tf.Module):
  def __init__(self, input_size, sizes, name=None):
    super().__init__(name=name)
    self.layers = []
    with self.name_scope:
      for size in sizes:
        self.layers.append(Dense(input_dim=input_size, output_size=size))
        input_size = size
  def __call__(self, x):
    for layer in self.layers:
      x = layer(x)
    return x




module = MLP(input_size=5, sizes=[5, 5])
(<tf.Variable 'mlp/b:0' shape=(5,) dtype=float32, numpy=..., dtype=float32)>,
<tf.Variable 'mlp/w:0' shape=(5, 5) dtype=float32, numpy=...,
   dtype=float32)>,
<tf.Variable 'mlp/b:0' shape=(5,) dtype=float32, numpy=..., dtype=float32)>,
<tf.Variable 'mlp/w:0' shape=(5, 5) dtype=float32, numpy=...,
   dtype=float32)>)




## Attributes
properties of modules which are properties of this module (and so on).


a = tf.Module()
b = tf.Module()
c = tf.Module()
a.b = b
b.c = c
list(a.submodules) == [b, c]
list(b.submodules) == [c]
list(c.submodules) == []




## Methods


### with_name_scope


with_name_scope(
    method
)




class MyModule(tf.Module):
  def __call__(self, x):
    if not hasattr(self, 'w'):
      self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))
    return tf.matmul(x, self.w)


Using the above module would produce tf.Variable s and tf.Tensor s whose


mod = MyModule()
mod(tf.ones([1, 2]))
<tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>
<tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,
numpy=..., dtype=float32)>


Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License , and code samples are licensed under the Apache 2.0 License . For details, see the Google Developers Site Policies . Java is a registered trademark of Oracle and/or its affiliates. Some content is licensed under the numpy license .

# Source: https://www.tensorflow.org/api_docs/python/tf/Module