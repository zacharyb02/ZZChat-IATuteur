

# tf.keras.optimizers.schedules.InverseTimeDecayStay organized with collectionsSave and categorize content based on your preferences.


tf.keras.optimizers.schedules.InverseTimeDecay(
    initial_learning_rate,
    decay_steps,
    decay_rate,
    staircase=False,
    name='InverseTimeDecay'
)




### Used in the notebooks
When training a model, it is often useful to lower the learning rate as
the training progresses. This schedule applies the inverse decay function
to an optimizer step, given a provided initial learning rate.
It requires a step value to compute the decayed learning rate. You can
just pass a backend variable that you increment at each training step.
rate when passed the current optimizer step. This can be useful for changing
the learning rate value across different invocations of optimizer functions.


def decayed_learning_rate(step):
    return initial_learning_rate / (1 + decay_rate * step / decay_step)




def decayed_learning_rate(step):
    return initial_learning_rate /
           (1 + decay_rate * floor(step / decay_step))


You can pass this schedule directly into a keras.optimizers.Optimizer as the learning rate.
Example: Fit a Keras model when decaying 1/t with a rate of 0.5:


initial_learning_rate = 0.1
decay_steps = 1.0
decay_rate = 0.5
learning_rate_fn = keras.optimizers.schedules.InverseTimeDecay(
    initial_learning_rate, decay_steps, decay_rate)
model.compile(optimizer=keras.optimizers.SGD(
                  learning_rate=learning_rate_fn),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(data, labels, epochs=5)




## Args
initial_learning_rate A Python float. The initial learning rate. decay_steps How often to apply decay. decay_rate A Python number.  The decay rate. staircase Whether to apply decay in a discrete staircase, as o
Returns A 1-arg callable learning rate schedule that takes the current optimizer
step and outputs the decayed learning rate, a scalar tensor of the


## Returns


## Methods


### from_config


from_config(
    config
)


config Output of get_config() .


### get_config


### __call__
Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License , and code samples are licensed under the Apache 2.0 License . For details, see the Google Developers Site Policies . Java is a registered trademark of Oracle and/or its affiliates. Some content is licensed under the numpy license .

# Source: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/InverseTimeDecay