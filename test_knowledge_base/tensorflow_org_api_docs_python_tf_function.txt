

# tf.functionStay organized with collectionsSave and categorize content based on your preferences.
Compiles a function into a callable TensorFlow graph. (deprecated arguments) (deprecated arguments) (deprecated arguments)


tf.function(
    func=None,
    input_signature=None,
    autograph=True,
    jit_compile=None,
    reduce_retracing=False,
    experimental_implements=None,
    experimental_autograph_options=None,
    experimental_attributes=None,
    experimental_relax_shapes=None,
    experimental_compile=None,
    experimental_follow_type_hints=None
) -> tf.types.experimental.PolymorphicFunction




### Used in the notebooks
- Import a JAX model using JAX2TF
- Custom training with tf.distribute.Strategy
- Distributed training with DTensors
- Parameter server training with ParameterServerStrategy
executes a TensorFlow graph ( tf.Graph ) created by trace-compiling the
TensorFlow operations in func . More information on the topic can be found


def f(x, y):
  return x ** 2 + y
x = tf.constant([2, 3])
y = tf.constant([3, -2])
f(x, y)
<tf.Tensor: ... numpy=array([7, 7], ...)>


The trace-compilation allows non-TensorFlow operations to execute, but under
special conditions. In general, only TensorFlow operations are guaranteed to


## Features
func may use data-dependent Python control flow statements, including if , for , while break , continue and return :


def f(x):
  if tf.reduce_sum(x) > 0:
    return x * x
    return -x // 2
f(tf.constant(-2))
<tf.Tensor: ... numpy=1>


func 's closure may include tf.Tensor and tf.Variable objects:


def f():
  return x ** 2 + y
x = tf.constant([-2, -3])
y = tf.Variable([3, -2])
f()
<tf.Tensor: ... numpy=array([7, 7], ...)>




v = tf.Variable(1)
def f(x):
  for i in tf.range(x):
    v.assign_add(i)
f(3)
<tf.Variable ... numpy=4>




l = []
def f(x):
    l.append(i + 1)    # Caution! Will only happen once when tracing
f(tf.constant([1, 2, 3]))
[<tf.Tensor ...>]


Instead, use TensorFlow collections like tf.TensorArray :


def f(x):
  ta = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)
  for i in range(len(x)):
    ta = ta.write(i, x[i] + 1)
  return ta.stack()
f(tf.constant([1, 2, 3]))
<tf.Tensor: ..., numpy=array([2, 3, 4], ...)>




## tf.functioncreates polymorphic callables
different data types or shapes, since TensorFlow can perform more
optimizations on graphs of specific shapes, dtypes and values of constant
arguments. tf.function treats any pure Python values as opaque objects (best
thought of as compile-time constants), and builds a separate tf.Graph for
same arguments as func and returns a tf.types.experimental.ConcreteFunction . ConcreteFunction s are backed by a


def f(x):
  return x + 1
isinstance(f.get_concrete_function(1).graph, tf.Graph)


input is resticted to the types to which they're specialized.


## Retracing
ConcreteFunctions are built (traced) on the fly, as the PolymorphicFunction is
called with new TensorFlow types or shapes, or with new Python values as


def f(x):
  return tf.abs(x)
f1 = f.get_concrete_function(1)
f2 = f.get_concrete_function(2)  # Slow - compiles new graph
f1 = f.get_concrete_function(tf.constant(1))
f2 = f.get_concrete_function(tf.constant(2))  # Fast - reuses f1


values, such as hyperparameters like the number of layers in a neural network.


## Input signatures
For Tensor arguments, PolymorphicFunction creates a new ConcreteFunction for
every unique set of input shapes and datatypes. The example below creates two
separate ConcreteFunction s, each specialized to a different shape:


def f(x):
  return x + 1
vector = tf.constant([1.0, 1.0])
matrix = tf.constant([[3.0]])
f.get_concrete_function(vector) is f.get_concrete_function(matrix)


An "input signature" can be optionally provided to tf.function to control
this process. The input signature specifies the shape and type of each
Tensor argument to the function using a tf.TensorSpec object. More general
shapes can be used. This ensures only one ConcreteFunction is created, and
restricts the PolymorphicFunction to the specified shapes and types. It is
an effective way to limit retracing when Tensors have dynamic shapes.


@tf.function(
    input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])
def f(x):
  return x + 1
vector = tf.constant([1.0, 1.0])
matrix = tf.constant([[3.0]])
f.get_concrete_function(vector) is f.get_concrete_function(matrix)




## Variables may only be created once


class MyModule(tf.Module):
  def __init__(self):
    self.v = None
  def __call__(self, x):
    if self.v is None:
      self.v = tf.Variable(tf.ones_like(x))
    return self.v * x


implemented using a pure functional style in which state is represented by tf.Tensor s passed as arguments and returned as return values.


state = tf.Variable(1)
def f(x):
  state.assign_add(x)
f(tf.constant(2))  # Non-pure functional style
<tf.Variable ... numpy=3>




state = tf.constant(1)
def f(state, x):
  state += x
  return state
state = f(state, tf.constant(2))  # Pure functional style
<tf.Tensor: ... numpy=3>




## Python operations execute only once per trace
func may contain TensorFlow operations mixed with pure Python operations.
However, when the function is executed, only the TensorFlow operations will
run. The Python operations run only once, at trace time. If TensorFlow


def f(a, b):
  print('this runs at trace time; a is', a, 'and b is', b)
  return b
f(1, tf.constant(1))
this runs at trace time; a is 1 and b is Tensor("...", shape=(), dtype=int32)
<tf.Tensor: shape=(), dtype=int32, numpy=1>




f(1, tf.constant(2))
<tf.Tensor: shape=(), dtype=int32, numpy=2>




f(2, tf.constant(1))
this runs at trace time; a is 2 and b is Tensor("...", shape=(), dtype=int32)
<tf.Tensor: shape=(), dtype=int32, numpy=1>




f(2, tf.constant(2))
<tf.Tensor: shape=(), dtype=int32, numpy=2>




## Args
func The function to be compiled. If func is None, tf.function returns
words, tf.function(input_signature=...)(func) is equivalent to tf.function(func, input_signature=...) . The former can be used as
decorator. input_signature A possibly nested sequence of tf.TensorSpec objects
specifying the shapes and dtypes of the Tensors that will be supplied to
inferred input signature.  If input_signature is specified, every input to func must be a Tensor , and func cannot accept **kwargs . autograph Whether autograph should be applied on func before tracing a
graph. Data-dependent Python control flow statements require autograph=True . For more information, see the tf.function and AutoGraph guide . jit_compile If True , compiles the function using XLA . XLA performs compiler optimizations,
If None (default), compiles the function with XLA when running on TPU
to False when directly running a multi-device function on TPUs (e.g. two
TPU cores, one TPU core and its host CPU).
amount of retracing, for example by using more generic shapes. This
implementations. For instance, a tensorflow user can use this
 attribute to mark that their function also implements embedded_matmul (perhaps more efficiently!)
by specifying it using this parameter: @tf.function(experimental_implements="embedded_matmul") This can either be specified as just the string name of the function or
generated FunctionDefs. experimental_relax_shapes Deprecated. Use reduce_retracing instead. experimental_compile Deprecated alias to 'jit_compile'. experimental_follow_type_hints Deprecated. Please use input_signature or
Returns If func is not None, returns a tf.types.experimental.PolymorphicFunction .
If func is None, returns a decorator that, when invoked with a single func argument, returns a tf.types.experimental.PolymorphicFunction .


## Returns
Raises ValueError when attempting to use jit_compile=True , but XLA support is


## Raises
Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License , and code samples are licensed under the Apache 2.0 License . For details, see the Google Developers Site Policies . Java is a registered trademark of Oracle and/or its affiliates. Some content is licensed under the numpy license .

# Source: https://www.tensorflow.org/api_docs/python/tf/function