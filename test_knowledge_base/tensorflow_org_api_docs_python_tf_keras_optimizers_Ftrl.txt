

# tf.keras.optimizers.FtrlStay organized with collectionsSave and categorize content based on your preferences.
Optimizer that implements the FTRL algorithm.


tf.keras.optimizers.Ftrl(
    learning_rate=0.001,
    learning_rate_power=-0.5,
    initial_accumulator_value=0.1,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    l2_shrinkage_regularization_strength=0.0,
    beta=0.0,
    weight_decay=None,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    loss_scale_factor=None,
    gradient_accumulation_steps=None,
    name='ftrl',
    **kwargs
)


"Follow The Regularized Leader" (FTRL) is an optimization algorithm
developed at Google for click-through rate prediction in the early 2010s. It
is most suitable for shallow models with large and sparse feature spaces.
The Keras version has support for both online L2 regularization
(the L2 regularization described in the paper
above) and shrinkage-type L2 regularization
(which is the addition of an L2 penalty to the loss function).


n = 0
sigma = 0
z = 0




prev_n = n
n = n + g ** 2
sigma = (n ** -lr_power - prev_n ** -lr_power) / lr
z = z + g - sigma * w
if abs(z) < lambda_1:
  w = 0
  w = (sgn(z) * lambda_1 - z) / ((beta + sqrt(n)) / alpha + lambda_2)


- g is the gradient for the variable
Check the documentation for the l2_shrinkage_regularization_strength parameter for more details when shrinkage is enabled, in which case gradient
is replaced with a gradient with shrinkage.


## Args
learning_rate A float, a keras.optimizers.schedules.LearningRateSchedule instance, or
a callable that takes no arguments and returns the actual value to
use. The learning rate. Defaults to 0.001 . learning_rate_power A float value, must be less or equal to zero.
Controls how the learning rate decreases during training. Use zero
for a fixed learning rate. initial_accumulator_value The starting value for accumulators. Only
magnitude penalty. When input is sparse shrinkage will only happen
on the active weights. beta A float value, representing the beta value from the paper.
for momentum accumulator weights created by
the optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually
clipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be
no higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped
(EMA) is applied. EMA consists of computing an exponential moving
average of the weights of the model (as the weight values change
after each training batch), and periodically overwriting the
weights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .
the EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *
current_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,
we overwrite the model variable by its moving average.
If None, the optimizer
does not overwrite model variables in the middle of training,
at the end of training by calling optimizer.finalize_variable_values() (which updates the model
variables in-place). When using the built-in fit() training loop,
this happens automatically after the last epoch,
and you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will
be multiplied the loss before computing gradients, and the inverse
of the scale factor will be multiplied by the gradients before
mixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will
automatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer
updated every gradient_accumulation_steps steps, using the average
value of the gradients since the last update. This is known as
"gradient accumulation". This can be useful
when your batch size is very small, in order to reduce gradient


## Attributes


## Methods


### add_variable


add_variable(
    shape,
    initializer='zeros',
    dtype=None,
    aggregation='mean',
    name=None
)




### add_variable_from_reference


add_variable_from_reference(
    reference_variable, name=None, initializer='zeros'
)


Add an all-zeros variable with the shape and dtype of a reference variable.


### apply


apply(
    grads, trainable_variables=None
)


Update traininable variables according to provided gradient values.
grads should be a list of gradient tensors
with 1:1 mapping to the list of variables the optimizer was built with.
on the first call to build the optimizer.


### apply_gradients


apply_gradients(
    grads_and_vars
)




### assign


assign(
    variable, value
)


This should be used in optimizers instead of variable.assign(value) to
Note that the variable can be a model variable or an optimizer variable;
it can be a backend native variable or a Keras variable.


### assign_add


assign_add(
    variable, value
)


This should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.
Note that the variable can be a model variable or an optimizer variable;
it can be a backend native variable or a Keras variable.


### assign_sub


assign_sub(
    variable, value
)


This should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.
Note that the variable can be a model variable or an optimizer variable;
it can be a backend native variable or a Keras variable.


### build


build(
    var_list
)


Initialize optimizer variables.
var_list list of model variables to build Ftrl variables on.


### exclude_from_weight_decay


exclude_from_weight_decay(
    var_list=None, var_names=None
)


This method must be called before the optimizer's build method is
in the model variable's name, then this model variable is
excluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.


### finalize_variable_values


finalize_variable_values(
    var_list
)


Set the final value of model's trainable variables.
such as overriding the model variables with its average value.
var_list list of model variables.


### from_config


from_config(
    config, custom_objects=None
)


Creates an optimizer from its config.
same optimizer from the config dictionary.
config A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional
user-defined Python objects needed to recreate this optimizer.


### get_config
Returns the config of the optimizer.
An optimizer config is a Python dictionary (serializable)
containing the configuration of an optimizer.
The same optimizer can be reinstantiated later
(without any saved state) from this configuration.
Subclass optimizer should override this method to include other


### load_own_variables


load_own_variables(
    store
)


Set the state of this optimizer object.


### save_own_variables


save_own_variables(
    store
)


Get the state of this optimizer object.


### scale_loss


scale_loss(
    loss
)


Scale the loss before computing gradients.
Scales the loss before gradients are computed in a train_step . This
is primarily useful during mixed precision training to prevent numeric


### set_weights


set_weights(
    weights
)


Set the weights of the optimizer.


### stateless_apply


stateless_apply(
    optimizer_variables, grads, trainable_variables
)




### update_step


update_step(
    gradient, variable, learning_rate
)


Update step given gradient and the associated model variable.
Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License , and code samples are licensed under the Apache 2.0 License . For details, see the Google Developers Site Policies . Java is a registered trademark of Oracle and/or its affiliates. Some content is licensed under the numpy license .

# Source: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Ftrl