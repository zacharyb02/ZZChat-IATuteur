

# tf.train.CheckpointManagerStay organized with collectionsSave and categorize content based on your preferences.


tf.train.CheckpointManager(
    checkpoint,
    directory,
    max_to_keep,
    keep_checkpoint_every_n_hours=None,
    checkpoint_name='ckpt',
    step_counter=None,
    checkpoint_interval=None,
    init_fn=None
)




### Used in the notebooks
- tf.data: Build TensorFlow input pipelines
- Distributed training with DTensors
- Custom training loop with Keras and MultiWorkerMirroredStrategy
- Multi-worker training with Keras


import tensorflow as tf
checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)
manager = tf.train.CheckpointManager(
    checkpoint, directory="/tmp/model", max_to_keep=5)
status = checkpoint.restore(manager.latest_checkpoint)
  # train
  manager.save()


CheckpointManager preserves its own state across instantiations (see the __init__ documentation for details). Only one should be active in a


## Args
special file named "checkpoint" is also written to this directory (in a
human-readable text format) which contains the state of the CheckpointManager . max_to_keep An integer, the number of checkpoints to keep. Unless
stays in the active set. Note that max_to_keep=None will keep all


## Raises


## Attributes
show up in this list (to avoid ever-growing filename lists). directory
latest_checkpoint The prefix of the most recent checkpoint in directory .
Equivalent to tf.train.latest_checkpoint(directory) where directory is
Suitable for passing to tf.train.Checkpoint.restore to resume training.


## Methods


### restore_or_initialize


restore_or_initialize()


Restore items in checkpoint from the latest checkpoint file.
models.
Note that unlike tf.train.Checkpoint.restore() , this method doesn't return
(e.g. assert_consumed()). Thus to run assertions, users should directly use tf.train.Checkpoint.restore() method.
Returns The restored checkpoint path if the lastest checkpoint is found and


### save


save(
    checkpoint_number=None, check_interval=True, options=None
)


checkpoint_number An optional integer, or an integer-dtype Variable or Tensor , used to number the checkpoint. If None (default),
works with TF2 checkpoint objects. For example, options =
tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')
Returns The path to the new checkpoint. It is also recorded in the checkpoints and latest_checkpoint properties. None if no checkpoint is saved.


### sync
Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License , and code samples are licensed under the Apache 2.0 License . For details, see the Google Developers Site Policies . Java is a registered trademark of Oracle and/or its affiliates. Some content is licensed under the numpy license .

# Source: https://www.tensorflow.org/api_docs/python/tf/train/CheckpointManager